{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for spike sorting from .kwd data using the Pipeline of mountainsort (linux channel has pipeline)\n",
    "Uses:\n",
    "    - intan2kwik (https://github.com/zekearneodo/intan2kwik/blob/master/README.md)\n",
    "    - mountainlab suite(https://github.com/flatironinstitute/mountainlab-js)\n",
    "    - mountainsort https://github.com/flatironinstitute/mountainsort_examples/blob/master/README.md\n",
    "    - mountainsort examples https://github.com/flatironinstitute/mountainsort_examples/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-16 12:33:22,004 - root - INFO - Logger set\n",
      "2019-05-16 12:33:22,005 - root - INFO - Hostname zpikezorter\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from datetime import timedelta\n",
    "from importlib import reload\n",
    "\n",
    "# pipeline imports\n",
    "from pipefinch.neural.convert import intan\n",
    "from pipefinch.neural.sort.mountain import core as msc\n",
    "from pipefinch.h5tools.kwik import kutil\n",
    "from pipefinch.pipeline import probes\n",
    "\n",
    "\n",
    "from pipefinch.h5tools.kwik import kwdfunctions as kwdf\n",
    "\n",
    "from intan2kwik import kwd\n",
    "\n",
    "#mountainsort imports (for sorting)\n",
    "#import mountainlab_pytools.mlproc as mlp\n",
    "\n",
    "import logging\n",
    "\n",
    "# Setup the logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "        \n",
    "logger.info('Logger set')\n",
    "logger.info('Hostname {}'.format(socket.gethostname()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session parameters and raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipefinch.pipeline import filestructure as et\n",
    "reload(et)\n",
    "reload(kwd)\n",
    "\n",
    "sess_par = {'bird': 'b11j11',\n",
    "           'sess': '2019-03-19_3125_02',\n",
    "           'probe': 'probe_0', # probe to sort ('probe_0', 'probe_1') (to lookup in the rig_par which port to extract)\n",
    "            'sort': 0\n",
    "           }\n",
    "\n",
    "exp_struct = et.get_exp_struct(sess_par['bird'], sess_par['sess'], sess_par['sort'])\n",
    "\n",
    "# mountainsort parameters\n",
    "sort_params = {'adjacency_radius': -1,\n",
    "              'detect_threshold': 2,\n",
    "              'freq_min': 600}\n",
    "\n",
    "# differetn mountainsort parameters\n",
    "ds_params = {'detect_sign': -1}\n",
    "\n",
    "\n",
    "# convenient paths\n",
    "kwik_folder = exp_struct['folders']['kwik']\n",
    "msort_folder = exp_struct['folders']['msort']\n",
    "raw_folder = exp_struct['folders']['raw']\n",
    "kwd_path = exp_struct['files']['kwd']\n",
    "bin_path = exp_struct['files']['mda_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'folders': {'raw': '/mnt/microdrive/birds/b11j11/Ephys/raw/2019-03-19_3125_02',\n",
       "  'kwik': '/data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-19_3125_02',\n",
       "  'msort': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02'},\n",
       " 'files': {'par': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/params.json',\n",
       "  'set': '/mnt/microdrive/birds/b11j11/Ephys/raw/2019-03-19_3125_02/settings.isf',\n",
       "  'rig': '/mnt/microdrive/birds/b11j11/Ephys/raw/2019-03-19_3125_02/rig.json',\n",
       "  'kwd': '/data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-19_3125_02/streams.kwd',\n",
       "  'kwik': '/data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-19_3125_02/sort_0/spikes.kwik',\n",
       "  'kwe': '/data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-19_3125_02/events.kwe',\n",
       "  'mda_raw': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/raw.mda'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert the whole session to a .kwd file\n",
    "Conversion sends every .rhd file in the folder to a rec in the .kwd file (experiment.kwd in the session ss folder)\n",
    "All of the files and all of the channels are converted; filtering and subselection of sub-epochs and channels occurs later.\n",
    "The .kwd is raw data, only in a friendlier format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a file for the session for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-16 12:33:23,088 - intan2kwik.kwd - WARNING - File /data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-19_3125_02/streams.kwd already exists\n",
      "2019-05-16 12:33:23,089 - intan2kwik.kwd - WARNING - Will abort. To overwrite the existing file, use overwrite=True option\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Kwd file already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b00c1f85be7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## Convert the whole session to a kwd file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwik_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfirst_intan_hdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintan_to_kwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwd_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotempfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/intan2kwik/intan2kwik/kwd.py\u001b[0m in \u001b[0;36mintan_to_kwd\u001b[0;34m(folder, dest_file_path, rec, include_channels, board, single_rec, overwrite, notempfile)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Will abort. To overwrite the existing file, use overwrite=True option'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Kwd file already exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minclude_channels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Kwd file already exists"
     ]
    }
   ],
   "source": [
    "reload(kwd)\n",
    "## Convert the whole session to a kwd file\n",
    "os.makedirs(kwik_folder, exist_ok=True)\n",
    "first_intan_hdr, sess_pd = kwd.intan_to_kwd(raw_folder, kwd_path, overwrite=False, notempfile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update a session with subsequently recorded rhd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-16 12:33:24,647 - pipefinch.h5tools.kwik.kwdfunctions - INFO - updating kwd file /data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-19_3125_02/streams.kwd from folder /mnt/microdrive/birds/b11j11/Ephys/raw/2019-03-19_3125_02\n",
      "2019-05-16 12:33:24,915 - pipefinch.h5tools.kwik.kwdfunctions - INFO - No new files to add to the file\n"
     ]
    }
   ],
   "source": [
    "reload(kwdf)\n",
    "_, nu_pd, _ = kwdf.update_kwd(kwd_path, raw_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make .mda file with a set of recordings in a session\n",
    " - pick all in port A\n",
    " - get all rec within a time range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bit_depth</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>start_sample</th>\n",
       "      <th>start_time</th>\n",
       "      <th>channel_bit_volts</th>\n",
       "      <th>channel_names</th>\n",
       "      <th>channels_sample_rate</th>\n",
       "      <th>dig_channel_names</th>\n",
       "      <th>is_multiSampleRate_data</th>\n",
       "      <th>valid_samples</th>\n",
       "      <th>samples_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-19 17:16:29</td>\n",
       "      <td>[0.195, 0.195, 0.195, 0.195, 0.195, 0.195, 0.1...</td>\n",
       "      <td>[D-004, D-005, D-006, D-007, D-008, D-012, D-0...</td>\n",
       "      <td>[20000.0, 20000.0, 20000.0, 20000.0, 20000.0, ...</td>\n",
       "      <td>[DIN-00, DIN-01]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1177200.0, 1177200.0, 1177200.0, 1177200.0, 1...</td>\n",
       "      <td>1177200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bit_depth  name  sample_rate  start_sample          start_time  \\\n",
       "0         16     0      20000.0             0 2019-03-19 17:16:29   \n",
       "\n",
       "                                   channel_bit_volts  \\\n",
       "0  [0.195, 0.195, 0.195, 0.195, 0.195, 0.195, 0.1...   \n",
       "\n",
       "                                       channel_names  \\\n",
       "0  [D-004, D-005, D-006, D-007, D-008, D-012, D-0...   \n",
       "\n",
       "                                channels_sample_rate dig_channel_names  \\\n",
       "0  [20000.0, 20000.0, 20000.0, 20000.0, 20000.0, ...  [DIN-00, DIN-01]   \n",
       "\n",
       "   is_multiSampleRate_data                                      valid_samples  \\\n",
       "0                        0  [1177200.0, 1177200.0, 1177200.0, 1177200.0, 1...   \n",
       "\n",
       "   samples_count  \n",
       "0        1177200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the session meta\n",
    "pd_meta = kwdf.get_all_rec_meta(kwd_path)\n",
    "pd_meta.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick a time interval of the recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_time_span(meta_pd, start, span_minutes):\n",
    "    end = start + timedelta(minutes=span_minutes)\n",
    "    pd_selection = meta_pd.loc[meta_pd['start_time'].between(start, end)]\n",
    "    return pd_selection\n",
    "\n",
    "pd_meta_selection = select_time_span(pd_meta, pd_meta['start_time'][0]+ timedelta(minutes=0*12), 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 14:47:06')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_meta['start_time'].max() - pd_meta['start_time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "            101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
       "           dtype='int64', length=111)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for instance\n",
    "pd_meta_selection.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rig parameters\n",
    "rig_par_file = exp_struct['files']['rig']\n",
    "with open(rig_par_file, 'r') as fp:\n",
    "    rig_par = json.load(fp)\n",
    "\n",
    "# get the probe and the port where the probe was connected\n",
    "selected_probe = sess_par['probe']\n",
    "probe_port = rig_par['chan']['port'][selected_probe].strip('-')\n",
    "\n",
    "# get the channel indices of the probe's port\n",
    "wanted_chans = np.array([probe_port + '-'])  # all ephys channels\n",
    "\n",
    "chan_list = kwdf.get_all_chan_names(pd_meta_selection, chan_filt=wanted_chans)\n",
    "\n",
    "#all_rec_list = kutil.get_rec_list(exp_struct['files']['kwd'])\n",
    "selection_rec_list = np.unique(pd_meta_selection['name'])\n",
    "\n",
    "rec_chans = pd_meta.loc[pd_meta['name'] == selection_rec_list[0], 'channel_names'].values\n",
    "rec_chans_idx = kwdf.find_chan_names_idx(rec_chans[0], chan_list)\n",
    "\n",
    "# make the mda binary file\n",
    "bin_path = exp_struct['files']['mda_raw']\n",
    "os.makedirs(exp_struct['folders']['msort'], exist_ok=True)\n",
    "# bin_file = kwdf.kwd_to_binary(exp_struct['files']['kwd'],\n",
    "#                               exp_struct['files']['mda_raw'],\n",
    "#                               chan_list=chan_list,\n",
    "#                               rec_list=selection_rec_list, header='mda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts for sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep the files with their nice formats, locations and names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-16 12:33:41,781 - root - WARNING - Probe could not be made, probe or headstage not found 'carbon-fiber' in probes.py. Will sort with no geometry\n",
      "2019-05-16 12:33:41,783 - root - INFO - Created session par files /data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/params.json\n"
     ]
    }
   ],
   "source": [
    "reload(msc)\n",
    "file_paths, out_folder = msc.make_paths(exp_struct['folders']['msort'])\n",
    "os.makedirs(exp_struct['folders']['msort'], exist_ok=True)\n",
    "\n",
    "# make the probe file\n",
    "rec_chans = pd_meta.loc[pd_meta['name']==0, 'channel_names'].values\n",
    "rec_chans_idx = kwdf.find_chan_names_idx(rec_chans[0], chan_list)\n",
    "probe = rig_par['probe'][selected_probe]['model']\n",
    "headstage = rig_par['probe'][selected_probe]['headstage']\n",
    "probe_chans = rec_chans_idx - np.min(rec_chans_idx)\n",
    "# try to make a probe. If it is not possible, force adjacency_radius to -1.\n",
    "try:\n",
    "    probe_geom = probes.make_map(probe, probe_chans)\n",
    "    np.savetxt(file_paths['geom'], probe_geom, delimiter=',')\n",
    "except KeyError as err:\n",
    "    logger.warning('Probe could not be made, probe or headstage not found {} in probes.py. Will sort with no geometry'.format(err))\n",
    "    sort_params['adjacency_radius'] = -1\n",
    "\n",
    "# parameters to pass to the msort scripts\n",
    "ds_params.update({'samplerate': int(kwdf.get_sampling_rate(pd_meta, 0)), # required\n",
    "            })\n",
    "\n",
    "\n",
    "with open(file_paths['params'], 'w') as fp:\n",
    "    json.dump(ds_params, fp)\n",
    "    logger.info('Created session par files {}'.format(file_paths['params']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mda': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/raw.mda',\n",
       " 'params': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/params.json',\n",
       " 'geom': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/geom.csv',\n",
       " 'filt': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/filt.mda.prv',\n",
       " 'pre': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/pre.mda.prv',\n",
       " 'firings': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings.mda',\n",
       " 'firings_curated': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings_curated.mda',\n",
       " 'cluster_metrics': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/cluster_metrics.json',\n",
       " 'cluster_metrics_curated': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/cluster_metrics_curated.json'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detect_sign': -1, 'samplerate': 20000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test mountainsort method for reading sorting parameters\n",
    "msc.read_dataset_params(exp_struct['folders']['msort'])\n",
    "output_dir = os.path.join(exp_struct['folders']['msort'], 'sort_out');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting with a Pipeline\n",
    "If it works it's cool. If it fails, you have to disregard the Pipeline object and call msc.sort_dataset with dispatch_method='run' option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6fa94364c14d21b97a2baca8e7379e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JSProxyWidget(status='Not yet rendered')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mountainlab_pytools import mlproc as mlp\n",
    "Pipeline=mlp.initPipeline();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-16 12:37:53,846 - pipefinch.sort.mountain.comre - INFO - Bandpass filter\n",
      "2019-05-16 12:37:53,851 - pipefinch.sort.mountain.comre - INFO - Whitening\n",
      "2019-05-16 12:37:53,855 - pipefinch.sort.mountain.comre - INFO - Sorting\n",
      "/home/ezequiel/repos/pipefinch/pipefinch/neural/sort/mountain/core.py:207: UserWarning: Will sort with no geometry input\n",
      "  warnings.warn('Will sort with no geometry input')\n",
      "2019-05-16 12:37:53,859 - pipefinch.sort.mountain.comre - INFO - Getting cluster metrics\n",
      "2019-05-16 12:37:53,869 - pipefinch.sort.mountain.comre - INFO - Automatically curating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0017dd837a7a4296aa6bfedbdab1a758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Pipeline was failing, need to debug this ('NameError: name 'widgets' is not defined')\n",
    "\n",
    "with Pipeline:\n",
    "    msc.sort_dataset(file_paths=file_paths, **sort_params, dispatch_method='add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-16 11:41:06,824 - pipefinch.sort.mountain.comre - INFO - Bandpass filter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING: ml-run-process ephys.bandpass_filter --inputs timeseries:/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/raw.mda --parameters freq_max:6000 freq_min:600 samplerate:20000 --outputs timeseries_out:/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/filt.mda.prv\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[31mThis is only a warning: Unable to hard link file /data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/raw.mda -> /tmp/mountainlab-tmp/tempdir_922754fd88_5dxQaF/input_timeseries_dHtPAP4X.mda. Perhaps temporary directory is not on the same device as the output file directory. Copying instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-16 11:42:54,554 - pipefinch.sort.mountain.comre - INFO - Whitening\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34mProcess signature: 922754fd8893d25911a197178916d14793cb2286\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m{\"timeseries_out\":\"/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/filt.mda.prv\"}\u001b[0m\n",
      "\u001b[34mProcessing ouput - /data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/filt.mda.prv\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m{\"timeseries_out\":\"/tmp/mountainlab-tmp/output_922754fd8893d25911a197178916d14793cb2286_timeseries_out.mda\"}\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[34mProcessing ouput - /tmp/mountainlab-tmp/output_922754fd8893d25911a197178916d14793cb2286_timeseries_out.mda\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /home/ezequiel/anaconda3/envs/sort/bin/python3 /home/ezequiel/anaconda3/envs/sort/etc/mountainlab/packages/ml_ephys/preprocessing/preprocessing.py.mp ephys.bandpass_filter --_tempdir=/tmp/mountainlab-tmp/tempdir_922754fd88_5dxQaF --timeseries=/tmp/mountainlab-tmp/tempdir_922754fd88_5dxQaF/input_timeseries_dHtPAP4X.mda --timeseries_out=/tmp/mountainlab-tmp/tempdir_922754fd88_5dxQaF/output_timeseries_out.mda --freq_max=6000 --freq_min=600 --samplerate=20000\u001b[0m\n",
      "\u001b[34mChunk size: 30000, Padding: 3000, Num chunks: 8951, Num processes: 20\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 6487 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 3548 of 8951 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 8788 of 8951 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 7629 of 8951 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 8211 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 5913 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 4737 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 578 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 2941 of 8951 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 5319 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 1742 of 8951 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 7061 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 4142 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 1165 of 8951 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 2345 of 8951 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mElapsed time for processor ephys.bandpass_filter: 62.763 sec\u001b[0m\n",
      "\u001b[34mFinalizing output timeseries_out\u001b[0m\n",
      "\u001b[34m[ Creating output prv for timeseries_out ... ]\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "RUNNING: ml-run-process ephys.whiten --inputs timeseries:/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/filt.mda.prv --parameters --outputs timeseries_out:/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/pre.mda.prv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-16 11:44:45,513 - pipefinch.sort.mountain.comre - INFO - Sorting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34mProcess signature: 25db9f82a7ca96c8b1df78fc71ce39e656f9e805\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m{\"timeseries_out\":\"/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/pre.mda.prv\"}\u001b[0m\n",
      "\u001b[34mProcessing ouput - /data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/pre.mda.prv\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m{\"timeseries_out\":\"/tmp/mountainlab-tmp/output_25db9f82a7ca96c8b1df78fc71ce39e656f9e805_timeseries_out.mda\"}\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[34mProcessing ouput - /tmp/mountainlab-tmp/output_25db9f82a7ca96c8b1df78fc71ce39e656f9e805_timeseries_out.mda\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /home/ezequiel/anaconda3/envs/sort/bin/python3 /home/ezequiel/anaconda3/envs/sort/etc/mountainlab/packages/ml_ephys/preprocessing/preprocessing.py.mp ephys.whiten --_tempdir=/tmp/mountainlab-tmp/tempdir_25db9f82a7_XAurt7 --timeseries=/tmp/mountainlab-tmp/tempdir_25db9f82a7_XAurt7/input_timeseries_h6GTeaWf.mda --timeseries_out=/tmp/mountainlab-tmp/tempdir_25db9f82a7_XAurt7/output_timeseries_out.mda\u001b[0m\n",
      "\u001b[34mChunk size: 300000, Num chunks: 896, Num processes: 20\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 75 of 896 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 336 of 896 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 398 of 896 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 139 of 896 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 720 of 896 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 783 of 896 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 203 of 896 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 464 of 896 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 528 of 896 chunks...\u001b[0m\n",
      "\u001b[34mProcessed 848 of 896 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mProcessed 654 of 896 chunks...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mElapsed time for processor ephys.whiten: 58.248 sec\u001b[0m\n",
      "\u001b[34mFinalizing output timeseries_out\u001b[0m\n",
      "\u001b[34m[ Creating output prv for timeseries_out ... ]\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezequiel/repos/pipefinch/pipefinch/neural/sort/mountain/core.py:207: UserWarning: Will sort with no geometry input\n",
      "  warnings.warn('Will sort with no geometry input')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING: ml-run-process ms4alg.sort --inputs timeseries:/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/pre.mda.prv --parameters adjacency_radius:-1 detect_sign:-1 detect_threshold:2 --outputs firings_out:/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings.mda\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/ml_ms4alg/ms4alg.py\", line 577, in prepare_timeseries_hdf5\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[31mf.create_dataset('part-{}-{}'.format(m,j),data=padded_chunk[m,:].ravel())\u001b[0m\n",
      "\u001b[34mProcess signature: ba8e0f2758f9006d8df958c2af3fbab8e57dfd5d\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/h5py/_hl/group.py\", line 136, in create_dataset\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[31mdsid = dataset.make_new_dset(self, shape, dtype, data, **kwds)\u001b[0m\n",
      "\u001b[34m{\"firings_out\":\"/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings.mda\"}\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 170, in make_new_dset\u001b[0m\n",
      "\u001b[34mProcessing ouput - /data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings.mda\u001b[0m\n",
      "\u001b[31mdset_id.write(h5s.ALL, h5s.ALL, data)\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[31mFile \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[34m{\"firings_out\":\"/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings.mda\"}\u001b[0m\n",
      "\u001b[31mFile \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[31mFile \"h5py/h5d.pyx\", line 221, in h5py.h5d.DatasetID.write\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[31mFile \"h5py/_proxy.pyx\", line 132, in h5py._proxy.dset_rw\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[31mFile \"h5py/_proxy.pyx\", line 93, in h5py._proxy.H5PY_H5Dwrite\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[31mOSError: Can't write data (file write failed: time = Thu May 16 11:45:07 2019\u001b[0m\n",
      "\u001b[34mProcessing ouput - /data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings.mda\u001b[0m\n",
      "\u001b[31m, filename = '/tmp/mountainlab-tmp/tempdir_ba8e0f2758_LO4TJ6/timeseries.hdf5', file descriptor = 6, errno = 28, error message = 'No space left on device', buf = 0x7f57e5600910, total write size = 2182784, bytes this sub-write = 2182784, bytes actually written = 18446744073709551615, offset = 5491838976)\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[31mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34m[ Running ... ] /home/ezequiel/anaconda3/envs/sort/bin/python3 /home/ezequiel/anaconda3/envs/sort/etc/mountainlab/packages/ml_ms4alg/ms4alg_spec.py.mp ms4alg.sort --_tempdir=/tmp/mountainlab-tmp/tempdir_ba8e0f2758_LO4TJ6 --timeseries=/tmp/mountainlab-tmp/tempdir_ba8e0f2758_LO4TJ6/input_timeseries_PpqcBaRg.mda --geom= --firings_out=/tmp/mountainlab-tmp/tempdir_ba8e0f2758_LO4TJ6/output_firings_out.mda --adjacency_radius=-1 --detect_sign=-1 --detect_threshold=2\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34mUsing tempdir=/tmp/mountainlab-tmp/tempdir_ba8e0f2758_LO4TJ6\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[34mNum. workers = 20\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/etc/mountainlab/packages/ml_ms4alg/ms4alg_spec.py.mp\", line 13, in <module>\u001b[0m\n",
      "\u001b[34mPreparing /tmp/mountainlab-tmp/tempdir_ba8e0f2758_LO4TJ6/timeseries.hdf5...\u001b[0m\n",
      "\u001b[31mif not PM.run(sys.argv):\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/mountainlab_pytools/processormanager/processormanager_impl.py\", line 37, in run\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[31mreturn P(**args)\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/ml_ms4alg/p_ms4alg.py\", line 79, in sort\u001b[0m\n",
      "\u001b[31mMS4.sort()\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/ml_ms4alg/ms4alg.py\", line 650, in sort\u001b[0m\n",
      "\u001b[31mprepare_timeseries_hdf5(self._timeseries_path,temp_hdf5_path,chunk_size=hdf5_chunk_size,padding=hdf5_padding)\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/ml_ms4alg/ms4alg.py\", line 577, in prepare_timeseries_hdf5\u001b[0m\n",
      "\u001b[31mf.create_dataset('part-{}-{}'.format(m,j),data=padded_chunk[m,:].ravel())\u001b[0m\n",
      "\u001b[31mFile \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[31mFile \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/h5py/_hl/files.py\", line 442, in __exit__\u001b[0m\n",
      "\u001b[31mself.close()\u001b[0m\n",
      "\u001b[31mFile \"/home/ezequiel/anaconda3/envs/sort/lib/python3.6/site-packages/h5py/_hl/files.py\", line 424, in close\u001b[0m\n",
      "\u001b[31mh5i.dec_ref(id_)\u001b[0m\n",
      "\u001b[31mFile \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[31mFile \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\u001b[0m\n",
      "\u001b[31mFile \"h5py/h5i.pyx\", line 150, in h5py.h5i.dec_ref\u001b[0m\n",
      "\u001b[31mRuntimeError: Dirty entry flush destroy failed (file write failed: time = Thu May 16 11:45:07 2019\u001b[0m\n",
      "\u001b[31m, filename = '/tmp/mountainlab-tmp/tempdir_ba8e0f2758_LO4TJ6/timeseries.hdf5', file descriptor = 6, errno = 28, error message = 'No space left on device', buf = 0x5568f66a04c0, total write size = 9696, bytes this sub-write = 9696, bytes actually written = 18446744073709551615, offset = 1393528832)\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[31mSegmentation fault (core dumped)\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[31mProcess returned with non-zero exit code.\u001b[0m\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Non-zero exit code for ms4alg.sort",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-72ce2a78f1a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_struct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'folders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msort'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sort_out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msort_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/pipefinch/pipefinch/neural/sort/mountain/core.py\u001b[0m in \u001b[0;36msort_dataset\u001b[0;34m(file_paths, freq_min, freq_max, adjacency_radius, detect_threshold, dispatch_method, opts, no_auto_metrics)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mdetect_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetect_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mdispatch_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdispatch_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/pipefinch/pipefinch/neural/sort/mountain/core.py\u001b[0m in \u001b[0;36mms4alg_sort\u001b[0;34m(timeseries, geom, firings_out, detect_sign, adjacency_radius, detect_threshold, dispatch_method, opts)\u001b[0m\n\u001b[1;32m    210\u001b[0m                                            \u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                                            \u001b[0;34m{\u001b[0m\u001b[0;34m'firings_out'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfirings_out\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                            opts)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sort/lib/python3.6/site-packages/mountainlab_pytools/mlproc/mlproc_impl.py\u001b[0m in \u001b[0;36mrunProcess\u001b[0;34m(processor_name, inputs, outputs, parameters, opts)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unable to find processor:::: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpackage_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sort/lib/python3.6/site-packages/mountainlab_pytools/mlproc/mlproc_impl.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, inputs, outputs, parameters, opts)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_command_and_print_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Non-zero exit code for {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Non-zero exit code for ms4alg.sort"
     ]
    }
   ],
   "source": [
    "# If pipleine fails\n",
    "#msc.sort_dataset(file_paths=file_paths, **sort_params,  dispatch_method='run');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mda': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/raw.mda',\n",
       " 'params': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/params.json',\n",
       " 'geom': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/geom.csv',\n",
       " 'filt': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/filt.mda.prv',\n",
       " 'pre': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/pre.mda.prv',\n",
       " 'firings': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings.mda',\n",
       " 'firings_curated': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/firings_curated.mda',\n",
       " 'cluster_metrics': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/cluster_metrics.json',\n",
       " 'cluster_metrics_curated': '/data/experiment/microdrive/b11j11/Ephys/msort/2019-03-19_3125_02/sort_out/cluster_metrics_curated.json'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command for viewing:\n",
    " - open up terminal with the environment msort\n",
    " - go go the ss_data folder for the session\n",
    " - run the command: qt-mountainview --raw raw.mda --filt sort_out/filt.mda.prv --pre sort_out/pre.mda.prv --samplerate=20000 --firings sort_out/firings.mda --cluster_metrics sort_out/cluster_metrics.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After manual curation\n",
    " - save the curated spikes in the sort_out/firings_curated.mda\n",
    " - come back to the notebook and run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 10:28:28,647 - pipefinch.h5tools.kwik.kwikfunctions - INFO - Creating kwik file /data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-15_3125_01/sort_0/spikes.kwik from firings /mnt/scratch/experiment/b11j11/Ephys/msort/2019-03-15_3125_01/sort_out/firings_curated.mda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pipefinch.h5tools.kwik.kwikfunctions.MdaKwikWriter at 0x7f6246323d68>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipefinch.h5tools.kwik import kwikfunctions as kwkf\n",
    "reload(kwkf)\n",
    "reload(et)\n",
    "firings_to_save = 'firings_curated' # 'curated' or 'firings' for default_output\n",
    "\n",
    "metrics_to_save = 'cluster_metrics_curated' if firings_to_save == 'firings_curated' else 'cluster_metrics'\n",
    "kwkf.mda_to_kwik(exp_struct['files']['kwd'],\n",
    "                 exp_struct['files']['kwik'],\n",
    "                 file_paths[firings_to_save],\n",
    "                file_paths[metrics_to_save], \n",
    "                rec_in_binary=selection_rec_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_rec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 10:28:39,775 - pipefinch.neural.units - INFO - About to get all waveforms for 29 units in file /data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-15_3125_01/sort_0/spikes.kwik\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38044e700b29483c8288ff2ce682af29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeke/anaconda3/envs/mountain/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### extract all unit waveforms\n",
    "from pipefinch.neural import units\n",
    "reload(units)\n",
    "units.get_all_unit_waveforms(exp_struct['files']['kwik'], exp_struct['files']['kwd'], port=probe_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleanup the intermediate sort files and the mountainsort .mda files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 10:30:05,875 - pipefinch.pipeline.filestructure - INFO - removing (if exists) msort mda file /mnt/scratch/experiment/b11j11/Ephys/msort/2019-03-15_3125_01/raw.mda \n",
      "2019-03-20 10:30:06,602 - pipefinch.sort.mountain.comre - INFO - Cleaning up msort temp dir /mnt/scratch/experiment/mountainlab-tmp\n"
     ]
    }
   ],
   "source": [
    "reload(et)\n",
    "reload(msc)\n",
    "et.msort_cleanup(exp_struct)\n",
    "msc.clean_tmp_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'par': '/mnt/scratch/experiment/b11j11/Ephys/msort/2019-03-15_3125_01/params.json',\n",
       " 'set': '/mnt/zuperfinch/microdrive/birds/b11j11/Ephys/raw/2019-03-15_3125_01/settings.isf',\n",
       " 'rig': '/mnt/zuperfinch/microdrive/birds/b11j11/Ephys/raw/2019-03-15_3125_01/rig.json',\n",
       " 'kwd': '/data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-15_3125_01/streams.kwd',\n",
       " 'kwik': '/data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-15_3125_01/sort_0/spikes.kwik',\n",
       " 'kwe': '/data/experiment/microdrive/b11j11/Ephys/kwik/2019-03-15_3125_01/events.kwe',\n",
       " 'mda_raw': '/mnt/scratch/experiment/b11j11/Ephys/msort/2019-03-15_3125_01/raw.mda'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " exp_struct['files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sort",
   "language": "python",
   "name": "sort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
